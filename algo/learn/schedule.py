"""
This module defines the scheduling events.
"""
import numpy as np
import heapq
import itertools
from collections import OrderedDict
from params import args
from spark_env.wall_time import WallTime
from spark_env.executor import Executor, FreeExecutors, MovingExecutors
from job_generator import generate_jobs
from spark_env.task import Task
from spark_env.job import Job
import utils
# args.moving_delay can be replaced to introduce heterogenous communication overhead


class Schedule:
    """
    Define the scheduling events.
    """
    def __init__(self):
        self.np_random = np.random.RandomState()
        self.wall_time = WallTime()
        self.timeline = Timeline()

        self.executors = utils.OrderedSet()
        for exec_idx in range(args.exec_cap):
            self.executors.add(Executor(exec_idx))
        self.free_executors = FreeExecutors(self.executors)
        self.moving_executors = MovingExecutors()
        self.exec_commit = ExecutorCommit()

        # stages wait to be scheduled, these stages are the return of scheduling algorithms
        self.stage_selected = set()
        self.reward_calculator = RewardCalculator()

        self.exec_to_schedule = None                   # executors to be scheduled
        self.src_job = None
        self.num_src_exec = -1                         # number of execs to be scheduled
        self.jobs = None
        self.action_map = None                         # a ReversibleMap from act to stage
        self.finished_jobs = None                      # we track this for updating the action-to-stage map
        self.max_time = None

    def step(self, next_stage, limit):
        """
        One (scheduling event) step forward: with given actions as input, do scheduling and return a new state.
        :param next_stage: the next to-be-scheduled stage, generated by scheduling algorithm
        :param limit: the exec limit for the job of the next to-be-scheduled stage, generated by scheduling algorithm
        """
        assert next_stage not in self.stage_selected
        self.stage_selected.add(next_stage)

        # select the next-to-schedule executor (it is the first one in self.exec_to_schedule)
        # this executor was released beforehand by some finished stage (and stored in self.exec_to_schedule)
        # we select this exec actually not for scheduling, but just for getting the src of it
        # when we get the src of it, we can know moving delay is required or not
        # when schedule, all executors in self.exec_to_schedule will be scheduled
        executor = next(iter(self.exec_to_schedule))
        src = executor.job if executor.stage is None else executor.stage

        # get the num of valid executors for dispatching
        # if next_stage is None, it means currently no available stage to schedule, thus the scheduling algorithm returns None
        if next_stage is not None:
            # use_exec denotes the num of executors wait to be dispatched to next_stage
            # next_stage.num_tasks - next_stage.next_task_idx is the num of unfinished tasks in next_stage
            # self.exec_commit.stage_commit[next_stage] + self.moving_executors.count(next_stage) is the num of execs
            # which have been decided to be dispatched to next_stage
            # at last, do not forget we limit the maximum exec_num (this is one of the actions what the actor_network returns)
            # thus, use_exec is the num of need-to-add execs
            use_exec = min(
                (next_stage.num_tasks - next_stage.next_task_idx) -
                (self.exec_commit.stage_commit[next_stage] + self.moving_executors.count(next_stage)),
                limit
            )
        else:
            # if next_stage is none, just get the maximum exec_num we can use
            use_exec = limit
        assert use_exec > 0

        # submit a commitment
        # notice that self.exec_commit only stores the scheduling actions returned from scheduling algorithms!
        self.exec_commit.add(src, next_stage, use_exec)
        self.num_src_exec -= use_exec
        assert self.num_src_exec >= 0       # if this not fulfilled, sth. wrong with the limit return from scheduling algorithm

        if self.num_src_exec == 0:
            # no more schedulable execs, which starts a new scheduling round
            self.stage_selected.clear()     # the left selected stages cannot be scheduled any more, start all over again
            # all commitment all made, schedule these executors. Actually here is the real line we actually do scheduling events
            # in one step, we will do many scheduling events until no more runnable stages or no more free executors
            self.schedule()

        # now schedule has been made, update state. The new state will be send to scheduling algorithm to invoke next action
        while len(self.timeline) > 0 and self.num_src_exec == 0:
            new_time, item = self.timeline.pop()
            self.wall_time.update(new_time)  # forward to this time slot

            # according to the type of item, turn into different state
            if isinstance(item, Task):
                # ============== task finish event ==============
                # update scheduled stage's finished tasks num, frontier stages changed or not, job completed or not
                # do not forget free up the finished task's served exec!
                finished_task = item
                stage = finished_task.stage
                stage.num_finished_tasks += 1

                frontier_changed = False
                if stage.num_finished_tasks == stage.num_tasks:
                    # update frontier stages and corresponding vars
                    assert not stage.all_tasks_done
                    stage.all_tasks_done = True
                    stage.job.num_finished_stages += 1
                    stage.finish_time = self.wall_time.cur_time
                    frontier_changed = stage.job.update_frontier_stages(stage)

                # free up this executor
                self.redispatch_executor(finished_task.executor, frontier_changed)

                if stage.job.num_finished_stages == stage.job.num_stages:
                    # update job completion status
                    assert not stage.job.finished
                    stage.job.finished = True
                    stage.job.finish_time = self.wall_time.cur_time
                    self.remove_job(stage.job)

            elif isinstance(item, Job):
                # ============= new job arrives event =============
                # update jobs num, and the action-to-stage map. Besides, dispatch all free execs in global free pool to it
                job = item
                assert not job.arrived
                job.arrived = True
                self.jobs.add(job)
                self.add_job(job)
                self.action_map = get_act2stage(self.jobs)

                # dispatch existing free executors to this new job
                if len(self.free_executors[None]) > 0:
                    # dispatch free executors to the newly arrived job (if exist)
                    self.exec_to_schedule = utils.OrderedSet(self.free_executors[None])
                    self.src_job = None
                    self.num_src_exec = len(self.free_executors[None])

            elif isinstance(item, Executor):
                # ============= executor arrival event =============
                executor = item
                # get the destination (stage) of this executor
                stage = self.moving_executors.pop(executor)
                if stage is not None:
                    # the job (of this stage) is not yet finished when this executor arrives, bind this 'executor' to its arrived job
                    executor.job = stage.job
                    stage.job.executors.add(executor)
                if stage is not None and not stage.no_more_task:
                    # this stage is schedulable, directly schedule it
                    if stage in stage.job.frontier_stages:
                        # this stage is immediately runnable
                        task = stage.schedule(executor)
                        self.timeline.push(task.finish_time, task)
                    else:
                        # add this executor to the free executor pool of this job
                        self.free_executors.add(executor.job, executor)
                else:
                    # this stage is saturated or this job is finished, but the executor still arrives to it
                    # in this case, use backup schedule policy
                    self.backup_schedule(executor)

            else:
                print('Illegal event type!')
                exit(1)

        # compute reward
        reward = self.reward_calculator.get_reward(self.jobs, self.wall_time.cur_time)
        # no more decision to make: jobs all done or time is up
        done = self.num_src_exec == 0 and (len(self.timeline) == 0 or self.wall_time.cur_time >= self.max_time)
        if done:
            assert self.wall_time.cur_time >= self.max_time or len(self.jobs) == 0

        # return new state, reward and a flag indicates whether all jobs are finished
        # these return vars are the input of the scheduling algorithm
        return self.observe(), reward, done

    def redispatch_executor(self, executor, frontier_changed):
        """
        Dispatch a finished task's 'executor' to the other stages.
        """
        if executor.stage is not None and not executor.stage.no_more_task:
            # the stage which this executor previously worked on is not finished, just directly working on the next task!
            # This is wired because every scheduling event should be decided by the agent. However, considering the
            # principle of locality, do it like this can not only improve the efficiency, but also avoid invoking the
            # agent too many times
            task = executor.stage.schedule(executor)
            self.timeline.push(task.finish_time, task)
            return
        if frontier_changed:
            # consult all free executors
            src_job = executor.job       # get the job where the executor previously worked on
            # self.exec_commit[executor.stage] == self.exec_commit.commit[executor.stage] because of the __getitem__ func
            if len(self.exec_commit[executor.stage]) > 0:
                # if this executor is already arranged, just directly fulfill the corresponding commitment
                self.exec_to_schedule = {executor}
                self.schedule()                       # just directly schedule 'executor', thus {} is enough, no need to use OrderedSet()
            else:
                # this executor is not arranged beforehand, temporarily store to the previously served job's free pool
                self.free_executors.add(src_job, executor)
            # executor.job may change after self.schedule(), update is necessary
            self.exec_to_schedule = utils.OrderedSet(self.free_executors[src_job])
            self.src_job = src_job
            self.num_src_exec = len(self.free_executors[src_job])
        else:
            # only need to schedule this executor
            self.exec_to_schedule = {executor}
            if len(self.exec_commit[executor.stage]) > 0:
                # directly fulfill the commitment
                self.schedule()                       # just directly schedule 'executor', thus {} is enough, no need to use OrderedSet()
            else:
                # consult all executors on this stage
                # len(self.exec_to_schedule) != self.num_src_exec can happen
                self.src_job = executor.job
                self.num_src_exec = len(executor.stage.executors)

    def seed(self, seed):
        self.np_random.seed(seed)

    def add_job(self, job):
        self.moving_executors.add_job(job)
        self.free_executors.add_job(job)
        self.exec_commit.add_job(job)

    def schedule(self):
        """
        Do scheduling as exec_commits indicates. This behavior is end until no more exec_commit to made
        (all wait-for-scheduling stages are scheduled) or no more execs to dispatch.
        """
        executor = next(iter(self.exec_to_schedule))
        src = executor.job if executor.stage is None else executor.stage
        # schedule executors from the src (stage or job) until the commitment is fulfilled
        while len(self.exec_commit[src]) > 0 and len(self.exec_to_schedule) > 0:
            # now we try to allocate 'executor' to 'stage', we need to launch classified discussion
            stage = self.exec_commit.pop(src)
            executor = self.exec_to_schedule.pop()

            # mark the executor as busy because it is scheduled
            if self.free_executors.contain_executor(executor.job, executor):
                self.free_executors.remove(executor)

            if stage is None:
                # no schedule event to do, we can only temporarily store 'executor'
                # if the previously served job of this exec is not yet finished, add to its free pool
                # else add to the global free pool
                if executor.job is not None and any([not s.no_more_task for s in executor.job.stages]):
                    # this stage is silent, make the executor idle
                    self.free_executors.add(executor.job, executor)
                else:
                    # no job or stage to dispatch, just put into the free pool
                    self.free_executors.add(None, executor)

            elif not stage.no_more_task:
                # stage is not None and not finished yet
                if executor.job == stage.job:
                    # 'stage' and the previously served job of 'executor' is the same one,
                    # in this case, no moving delay incurred
                    if stage in stage.job.frontier_stages:
                        # this task is immediately runnable, schedule it
                        # =================================================================
                        # the following line is where the scheduling event actually happens
                        task = stage.schedule(executor)
                        self.timeline.push(task.finish_time, task)
                    else:
                        # no schedule event to do, we can only temporarily store 'executor'
                        self.free_executors.add(executor.job, executor)
                else:
                    # need to move this executor to another job, thus moving delay is necessary
                    # we do not schedule here, but push this event into timeline and process later
                    # (moving_delay records the content switch overhead of moving exec from one job to another job)
                    self.timeline.push(self.wall_time.cur_time + args.moving_delay, executor)
                    self.moving_executors.add(executor, stage)

            else:
                # stage is not None and finished, just re-dispatch this exec to another wait-for-execution stage
                self.backup_schedule(executor)

    def backup_schedule(self, executor):
        """
        This func is used as backup policy. We add this because a random policy or a learned policy in early
        iterations might schedule no executor to jobs. This func makes sure that all executors are working conservatively.
        The agent should learn to not rely on this func.
        """
        backup_scheduled = False
        if executor.job is not None:
            # try to schedule 'executor' on current job firstly
            for stage in executor.job.frontier_stages:
                if not self.saturated(stage):
                    # successfully schedule this executor to the next-to-run task of this stage
                    task = stage.schedule(executor)
                    self.timeline.push(task.finish_time, task)
                    backup_scheduled = True
                    break
        if not backup_scheduled:
            # try to schedule on any available stage
            # if succeed, the chosen stage must be different from executor.job, thus, add moving delay
            schedulable_stages = self.get_frontier_stages()
            if len(schedulable_stages) > 0:
                # we do not schedule here, but push this event into timeline and process later
                stage = next(iter(schedulable_stages))
                self.timeline.push(self.wall_time.cur_time + args.moving_delay, executor)
                self.moving_executors.add(executor, stage)
                backup_scheduled = True
        if not backup_scheduled:
            # no available stage, 'executor' is totally idle now, add into the global free pool
            self.free_executors.add(executor.job, executor)

    def saturated(self, stage):
        """
        A stage is saturated iff it is finished as plan, which means we dont need to schedule any execs to this stage any more.
        """
        expected_task_idx = stage.next_task_idx + self.exec_commit.stage_commit[stage] + self.moving_executors.count(stage)
        return expected_task_idx >= stage.num_tasks

    def get_frontier_stages(self):
        """
        Get all the frontier stages from all currently not finished jobs.
        Distinguish this from each job's job.frontier_stages. This is mainly (only) used for observation.
        In this class, 'frontier' can be interpreted as itself is unsaturated but all its parent stages are saturated.
        """
        frontier_stages = utils.OrderedSet()
        for job in self.jobs:
            for stage in job.stages:
                if stage not in self.stage_selected and not self.saturated(stage):
                    all_parents_saturated = True
                    for parent in stage.parent_stages:
                        if not self.saturated(parent):
                            all_parents_saturated = False
                            break
                    if all_parents_saturated:
                        frontier_stages.add(stage)
        return frontier_stages

    def get_binding_execs_num(self):
        """
        Get currently the num of binding execs to each job.
        """
        exec_lmt = {}              # {job: int}
        for job in self.jobs:
            if self.src_job == job:
                exec_lmt[job] = len(job.executors) - self.num_src_exec
            else:
                exec_lmt[job] = len(job.executors)
        return exec_lmt

    def observe(self):
        """
        What this func returns is the observation of current state.
        This observation is used as the input to the agent. The agent construct the
        feature matrix of this observation (state) and output a proper action.
        """
        return self.jobs, self.src_job, self.num_src_exec, self.get_frontier_stages(), \
            self.get_binding_execs_num(), self.exec_commit, self.moving_executors, self.action_map

    def remove_job(self, job):
        """
        Remove the job when it is finished. Only called when the job is finished.
        """
        for executor in list(job.executors):
            executor.detach_job()
        self.exec_commit.remove_job(job)
        self.free_executors.remove_job(job)
        self.moving_executors.remove_job(job)
        self.jobs.remove(job)
        self.finished_jobs.add(job)
        self.action_map = get_act2stage(self.jobs)

    def reset(self, max_time=np.inf):
        self.max_time = max_time
        self.wall_time.reset()
        self.timeline.reset()
        self.exec_commit.reset()
        self.moving_executors.reset()
        self.reward_calculator.reset()
        self.finished_jobs = utils.OrderedSet()
        self.stage_selected.clear()
        for executor in self.executors:
            executor.reset()
        self.free_executors.reset(self.executors)

        # regenerate jobs (note that self.jobs are only currently arrived jobs)
        self.jobs = generate_jobs(self.np_random, self.timeline, self.wall_time)
        self.action_map = get_act2stage(self.jobs)
        for job in self.jobs:
            self.add_job(job)
        self.src_job = None
        # all executors are schedulable
        self.num_src_exec = len(self.executors)
        self.exec_to_schedule = utils.OrderedSet(self.executors)


class Timeline:
    """
    Store the tuple (time, counter, job/task/executor).
    The pair could be
        - the time a new job arrives;
        - the time a task is finished;
        - the time an executor arrives to anther job (this happens only when we moving executors, i.e. moving delay incurred).
    """
    def __init__(self):
        """
        self.pq (priority queue) stores the tuple: (key, counter, item).
        """
        self.pq = []
        self.counter = itertools.count()      # count starts from 0

    def __len__(self):
        return len(self.pq)

    def push(self, key, item):
        heapq.heappush(self.pq, (key, next(self.counter), item))

    def pop(self):
        """
        Pop the first (key, item) pair from the heap.
        """
        if len(self.pq) > 0:
            key, _, item = heapq.heappop(self.pq)
            return key, item
        return None, None

    def reset(self):
        self.pq = []
        self.counter = itertools.count()


class RewardCalculator:
    """
    Use the execution time for now to calculate the reward.
    For every job still in system, reward will add the negative of the job's executing time till now (of course with scaled factor).
    Obviously, longer each job's execution time, more punishment the Agent receives.
    """
    def __init__(self):
        self.jobs = set()                   # jobs that not finished during [prev_time, cur_time)
        self.prev_time = 0                  # previous reward calculation time

    def get_reward(self, jobs, cur_time):
        reward = 0
        for job in jobs:
            self.jobs.add(job)

        if args.learn_obj == 'mean':
            for job in list(self.jobs):
                reward -= (min(job.finish_time, cur_time) - max(job.start_time, self.prev_time)) / args.reward_scale
                if job.finished:
                    self.jobs.remove(job)
        elif args.learn_job == 'makespan':
            reward -= (cur_time - self.prev_time) / args.reward_scale
        else:
            print('Unsupported learn object!')
            exit(1)

        self.prev_time = cur_time
        return reward

    def reset(self):
        self.jobs.clear()
        self.prev_time = 0


class ExecutorCommit:
    """
    self.commit is a dict, where each key-value pair is {stage/job: OrderedDict(stage: amount)}.
    The key is the previously served stage/job of the first exec in self.exec_to_schedule, the value is
    an ordered dict where
        - the key is the next to-be-scheduled stage, and
        - the value is the num of executors allocated to it.
    """
    def __init__(self):
        self.commit = {}             # {src stage/job: OrderedDict(next_stage: amount of allocated execs)}
        self.stage_commit = {}       # {next_stage: amount of allocated execs}
        self.backward = {}           # {next_stage: set(src stages/jobs)}

    def __getitem__(self, src):
        return self.commit[src]

    def add(self, src, stage, amount):
        """
        Add a scheduling commitment.
        :param src: the first to-be-scheduled exec previously served job (or stage)
        :param stage: the next-to-schedule stage returned from the scheduling algorithm (agent)
        :param amount: the amount of execs need to allocate to the next-to-schedule stage
        (calculated according to the limit returned from the scheduling algorithm (agent))
        """
        # if non-exist then create
        if stage not in self.commit[src]:
            self.commit[src][stage] = 0
        # add
        self.commit[src][stage] += amount
        self.stage_commit[stage] += amount
        self.backward[stage].add(src)

    def pop(self, src):
        assert src in self.commit
        assert len(self.commit[src]) > 0

        stage = next(iter(self.commit[src]))
        # deduct
        self.commit[src][stage] -= 1
        self.stage_commit[stage] -= 1
        assert self.commit[src][stage] >= 0
        assert self.stage_commit[stage] >= 0
        # remove if amount is zero
        if self.commit[src][stage] == 0:
            del self.commit[src][stage]
            self.backward[stage].remove(src)

        return stage

    def add_job(self, job):
        self.commit[job] = OrderedDict()
        for stage in job.stages:
            self.commit[stage] = OrderedDict()
            self.stage_commit[stage] = 0
            self.backward[stage] = set()

    def remove_job(self, job):
        assert len(self.commit[job]) == 0
        del self.commit[job]
        for stage in job.stages:
            assert len(self.commit[stage]) == 0
            del self.commit[stage]

            for src in self.backward[stage]:
                del self.commit[src][stage]
            del self.backward[stage]
            del self.stage_commit[stage]

    def reset(self):
        self.commit = {None: OrderedDict()}
        self.stage_commit = {None: 0}
        self.backward = {None: set()}


def get_act2stage(jobs):
    """
    Get the translation from the action (an integer between [0, num_stages_in_all_jobs]) to the corresponding stage.
    """
    act2stage = utils.ReversibleMap()
    act = 0
    for job in jobs:
        for stage in job.stages:
            act2stage[act] = stage     # because of the __setitem__ function
            act += 1
    return act2stage
